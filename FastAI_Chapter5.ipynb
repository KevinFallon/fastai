{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNG22aWl2U8rrMMOKUKFRwp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KevinFallon/fastai/blob/main/FastAI_Chapter5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "ggu4C6KbDGeZ",
        "outputId": "2612b344-919d-4a27-ee61-50b615da86db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 719 kB 1.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 451 kB 11.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 45.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 5.5 MB 12.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 52.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 212 kB 58.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 182 kB 57.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 115 kB 61.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 127 kB 55.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 55.2 MB/s \n",
            "\u001b[?25hMounted at /content/gdrive\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='356622336' class='' max='811706944' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      43.93% [356622336/811706944 00:28&lt;00:35]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "! [ -e /content ] && pip install -Uqq fastbook\n",
        "import fastbook\n",
        "fastbook.setup_book()\n",
        "from fastbook import *\n",
        "from fastai.vision.all import *\n",
        "path = untar_data(URLs.PETS)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Path.BASE_PATH = path\n",
        "path.ls()"
      ],
      "metadata": {
        "id": "3oUgm9p0DcoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(path/\"images\").ls()"
      ],
      "metadata": {
        "id": "342QPdlJDrJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fname = (path/\"images\").ls()[0]\n",
        "print(fname)\n",
        "re.findall(r'(.+)_\\d+.jpg$', fname.name)"
      ],
      "metadata": {
        "id": "6nYIxAmQEJ9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pets = DataBlock(blocks = (ImageBlock, CategoryBlock),\n",
        "                 get_items=get_image_files,\n",
        "                 splitter=RandomSplitter(seed=42),\n",
        "                 get_y=using_attr(RegexLabeller(r'(.+)_\\d+.jpg$'), 'name'),\n",
        "                 # The two lines after this are for \"Presizing\"\n",
        "                 item_tfms=Resize(460),\n",
        "                 batch_tfms=aug_transforms(size=224, min_scale=0.75))\n",
        "\n",
        "'''\n",
        "Presizing is a way to do image augmentation that is designed to minimize data\n",
        "destruction while maintaining good performance. We need images to have the same\n",
        "dimensions so they can collate into tensors to be passed to the GPU. Additionally,\n",
        "we want to minimize the number of distinct augmentation computations we pefrom. \n",
        "\n",
        "\n",
        "transform images into uniform sizes for more efficient processing on the GPU.\n",
        "\n",
        "Presizing strategies:\n",
        "1. Resize images to relatively \"large\" dimensions. Dimenions significantly larger\n",
        "than the target training dimensions.\n",
        "2. Compose all the common augmentation operations into one and perform combined\n",
        "operation on the GPU only at the end of processing, rather than performing operations individually\n",
        "and interpolating multiple times.\n",
        "'''\n",
        "dls = pets.dataloaders(path/'images')"
      ],
      "metadata": {
        "id": "e1vRs-0XExux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "key = os.environ.get('AZURE_SEARCH_KEY', '0302a1f901a545f2986fcdd53310b214')\n",
        "results = search_images_bing(key, 'grizzly bear')\n",
        "ims = results.attrgot('contentUrl')\n",
        "# print(ims)\n",
        "\n",
        "from fastdownload import download_url\n",
        "dest = Path.cwd()/'images'/'grizzly.jpg'\n",
        "download_url(ims[0], dest, show_progress=False)\n",
        "im = Image.open(dest)\n",
        "im.to_thumb(256, 256)"
      ],
      "metadata": {
        "id": "A_4g3iRxLg7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dblock1 = DataBlock(blocks=(ImageBlock(), CategoryBlock()),\n",
        "                    get_y=parent_label,\n",
        "                    item_tfms=Resize(460),\n",
        ")\n",
        "\n",
        "dls1 = dblock1.dataloaders([(Path.cwd()/'images'/'grizzly.jpg')]*100, bs=4)\n",
        "dls1.train.get_idxs = lambda: Inf.ones\n",
        "# x is independent variable, so a TensorImage\n",
        "# y is dependent variable, so a 1 rank tensor of size `bs` representing possible\n",
        "# categories.\n",
        "x,y = dls1.valid.one_batch()\n",
        "_, axs = subplots(1, 2)\n",
        "\n",
        "x1 = TensorImage(x.clone())\n",
        "print(\"before\")\n",
        "print(x1.size())\n",
        "x1 = x1.affine_coord(sz=224)\n",
        "print(\"after\")\n",
        "print(x1.size())\n",
        "x1 = x1.rotate(draw=30, p=1.)\n",
        "x1 = x1.zoom(draw=1.2, p=1.)\n",
        "x1 = x1.warp(draw_x=-0.2, draw_y=0.2, p=1.0)\n",
        "\n",
        "tfms = setup_aug_tfms([Rotate(draw=30, p=1, size=224), Zoom(draw=1.2, p=1., size=224),\n",
        "                       Warp(draw_x=-0.2, draw_y=0.2, p=1., size=224)])\n",
        "pipeline = Pipeline(tfms)\n",
        "x = pipeline(x)\n",
        "TensorImage(x[0]).show(ctx=axs[0])\n",
        "TensorImage(x1[0]).show(ctx=axs[1]);\n",
        "'''\n",
        "It has been found thatin practice using presizing significantly improves the\n",
        "accuracy of models, and often results in speedups too.\n",
        "'''"
      ],
      "metadata": {
        "id": "KARoe5RWJDov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "its easy to make unnoticed mistakes while setting up the datablock so its important\n",
        "to verify the labeled data appears to be correct.\n",
        "'''\n",
        "dls.show_batch(nrows=1, ncols=3)"
      ],
      "metadata": {
        "id": "KuJakpWgcBvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this is an example of which we forget to set the resize function. its useful\n",
        "# to use the 'summary' method to check for mistakes.\n",
        "pets1 = DataBlock(blocks = (ImageBlock, CategoryBlock),\n",
        "                  get_items=get_image_files,\n",
        "                  splitter=RandomSplitter(seed=42),\n",
        "                  get_y=using_attr(RegexLabeller(r'(.+)_\\d+.jpg$'), 'name'))\n",
        "# purposely fails with an error describing non-consistent sizing of images\n",
        "# pets1.summary(path/'images')"
      ],
      "metadata": {
        "id": "wnwP5ieldEAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "it's important to train any model asap so we can some insight on how to best proceed and iterate\n",
        "is the data good enough? maybe we already have a good enough model and dont need to spend\n",
        "additional engineering time on new features\n",
        "'''\n",
        "learn = vision_learner(dls, resnet34, metrics=error_rate)\n",
        "learn.fine_tune(2)"
      ],
      "metadata": {
        "id": "2ICBdQyCdi0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "cross-entropy loss is what the fastai library uses for image data as input\n",
        "with a categorical output. fastai tries its best to choose an appropriate loss\n",
        "function when its not supplied.\n",
        "cross-entropy loss function has 2 benefits:\n",
        "1. it works even when our dependent variable has more than two categories\n",
        "2. it results in faster and more reliable training.\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "x, y = dls.one_batch()"
      ],
      "metadata": {
        "id": "9LPgP6O4LUTZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}